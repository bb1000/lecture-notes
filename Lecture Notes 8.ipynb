{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12ecf94a",
   "metadata": {},
   "source": [
    "# Lecture Notes 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9c0d58",
   "metadata": {},
   "source": [
    "## parametrized tests\n",
    "\n",
    "Consider\n",
    "\n",
    "~~~\n",
    "import green2red\n",
    "\n",
    "def test_conversion_ratio_trivial():\n",
    "    calculated = green2red.get_conversion_ratio(3, 3, 40)\n",
    "    expected = 0\n",
    "    assert calculated == expected\n",
    "\n",
    "def test_conversion_ratio():\n",
    "    calculated = green2red.get_conversion_ratio(3, 1.5, 40)\n",
    "    expected = 0.039\n",
    "    assert abs(calculated - expected) < .001\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2292885e",
   "metadata": {},
   "source": [
    "Instead of two testfunctions with explicit values we can introduce a parametrized test with the pytest framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ce79e0",
   "metadata": {},
   "source": [
    "~~~\n",
    "@pytest.mark.parametrize(\n",
    "    'req, avail, cream, repl',\n",
    "    [\n",
    "        (3, 3, 40, 0),\n",
    "        (3, 1.5, 40, 0.039),\n",
    "    ]\n",
    ")\n",
    "def test_conversion_ratio(req, avail, cream, repl):\n",
    "    calculated = green2red.get_conversion_ratio(req, avail, cream)\n",
    "    expected = repl\n",
    "    assert abs(calculated - expected) < .001\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45769fe",
   "metadata": {},
   "source": [
    "* The test values replace the arguments in the test function\n",
    "* Allows for generalization to testing many values without duplication code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8cd41e",
   "metadata": {},
   "source": [
    "Likewise, in the leap year example we have\n",
    "~~~\n",
    ">>> def test_leap_year():\n",
    "...     assert is_leap_year(2000) == True\n",
    "...     assert is_leap_year(1999) == False\n",
    "...     assert is_leap_year(1998) == False\n",
    "...     assert is_leap_year(1996) == True\n",
    "...     assert is_leap_year(1900) == False\n",
    "...     assert is_leap_year(1800) == False\n",
    "...     assert is_leap_year(1600) == True\n",
    "~~~\n",
    "vs\n",
    "~~~\n",
    "@pytest.mark.parametrize(\n",
    "    'year, is_leap',\n",
    "    [\n",
    "        (2000, True),\n",
    "        (1999, False),\n",
    "        (1998, False),\n",
    "        (1996, True),\n",
    "        (1900, False),\n",
    "        (1800, False),\n",
    "        (1600, True),\n",
    "    ]\n",
    ")\n",
    "def test_leap_year(year, is_leap):\n",
    "    assert is_leap_year(year) == is_leap\n",
    "~~~\n",
    "\n",
    "Running the test suite in the latter case reports as if there had been separate test functions for each value\n",
    "\n",
    "~~~\n",
    "============================= test session starts ==============================\n",
    "\n",
    "test_leap_year.py::test_leap_year[2000-True] PASSED                      [ 14%]\n",
    "test_leap_year.py::test_leap_year[1999-False] PASSED                     [ 28%]\n",
    "test_leap_year.py::test_leap_year[1998-False] PASSED                     [ 42%]\n",
    "test_leap_year.py::test_leap_year[1996-True] PASSED                      [ 57%]\n",
    "test_leap_year.py::test_leap_year[1900-False] PASSED                     [ 71%]\n",
    "test_leap_year.py::test_leap_year[1800-False] PASSED                     [ 85%]\n",
    "test_leap_year.py::test_leap_year[1600-True] PASSED                      [100%]\n",
    "\n",
    "============================== 7 passed in 0.01s ===============================\n",
    "\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac50fc9",
   "metadata": {},
   "source": [
    "### test coverage\n",
    "\n",
    "* used to measure how well code is tested\n",
    "* it requies an addition module, a pytest plugin\n",
    "\n",
    "~~~\n",
    "$ conda install pytest-cov\n",
    "~~~\n",
    "\n",
    "Now additional options are reported\n",
    "\n",
    "~~~\n",
    "$ pytest -v test_leap_year.py --cov leap_year \n",
    "---------- coverage: platform linux, python 3.11.0-final-0 -----------\n",
    "Name           Stmts   Miss  Cover\n",
    "----------------------------------\n",
    "leap_year.py       4      0   100%\n",
    "----------------------------------\n",
    "TOTAL              4      0   100%\n",
    "\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ce10af",
   "metadata": {},
   "source": [
    "## Sample exercises with pytest from codechalleng.es\n",
    "\n",
    "The tests contains pytest builtin tools, \n",
    "\n",
    "* during the tests pytest captures output from e.g. the print functions\n",
    "* in the test, it is possible to retrieve the printed text with the [capfd fixture](https://docs.pytest.org/en/7.1.x/how-to/capture-stdout-stderr.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327e5848",
   "metadata": {},
   "source": [
    "### test_driving.py\n",
    "~~~\n",
    "from driving import allowed_driving\n",
    "\n",
    "\n",
    "def test_not_allowed_to_drive(capfd):\n",
    "    allowed_driving('tim', 17)\n",
    "    output = capfd.readouterr()[0].strip()\n",
    "    assert output == 'tim is not allowed to drive'\n",
    "\n",
    "\n",
    "def test_allowed_to_drive(capfd):\n",
    "    allowed_driving('bob', 18)\n",
    "    output = capfd.readouterr()[0].strip()\n",
    "    assert output == 'bob is allowed to drive'\n",
    "\n",
    "\n",
    "def test_allowed_to_drive_other_name(capfd):\n",
    "    allowed_driving('julian', 19)\n",
    "    output = capfd.readouterr()[0].strip()\n",
    "    assert output == 'julian is allowed to drive'\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8eb02af",
   "metadata": {},
   "source": [
    "### driving.py\n",
    "~~~\n",
    "MIN_DRIVING_AGE = 18\n",
    "\n",
    "\n",
    "def allowed_driving(name, age):\n",
    "    \"\"\"Print '{name} is allowed to drive' or '{name} is not allowed to drive'\n",
    "       checking the passed in age against the MIN_DRIVING_AGE constant\"\"\"\n",
    "    if age < MIN_DRIVING_AGE:\n",
    "        print(f'{name} is not allowed to drive')\n",
    "    else:\n",
    "        print(f'{name} is allowed to drive')\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07273a6f",
   "metadata": {},
   "source": [
    "~~~\n",
    "============================= test session starts ==============================\n",
    "...\n",
    "\n",
    "test_driving.py::test_not_allowed_to_drive PASSED                        [ 33%]\n",
    "test_driving.py::test_allowed_to_drive PASSED                            [ 66%]\n",
    "test_driving.py::test_allowed_to_drive_other_name PASSED                 [100%]\n",
    "\n",
    "============================== 3 passed in 0.01s ===============================\n",
    "\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69065035",
   "metadata": {},
   "source": [
    "### test_colors.py\n",
    "\n",
    "~~~\n",
    "from unittest.mock import patch\n",
    "\n",
    "from colors import print_colors\n",
    "\n",
    "NOT_VALID = 'Not a valid color'\n",
    "\n",
    "\n",
    "def call_print_colors():\n",
    "    # some people prefer sys.exit instead of break\n",
    "    try:\n",
    "        print_colors()\n",
    "    except SystemExit:\n",
    "        pass\n",
    "\n",
    "\n",
    "@patch(\"builtins.input\", side_effect=['quit'])\n",
    "def test_straight_quit(input_mock, capsys):\n",
    "    # user only enter quit, program prints bye and breaks loop\n",
    "    call_print_colors()\n",
    "    actual = capsys.readouterr()[0].strip()\n",
    "    expected = 'bye'\n",
    "    assert actual == expected\n",
    "\n",
    "\n",
    "@patch(\"builtins.input\", side_effect=['blue', 'quit'])\n",
    "def test_one_valid_color_then_quit(input_mock, capsys):\n",
    "    # user enters blue = valid color so print it\n",
    "    # then user enters quit so break out of loop = end program\n",
    "    call_print_colors()\n",
    "    actual = capsys.readouterr()[0].strip()\n",
    "    expected = 'blue\\nbye'\n",
    "    assert actual == expected\n",
    "\n",
    "\n",
    "@patch(\"builtins.input\", side_effect=['Blue', 'quit'])\n",
    "def test_title_cased_color_is_fine_too(input_mock, capsys):\n",
    "    # user enters Blue = valid color, program needs to lowercase it\n",
    "    # then user enters quit so break out of loop = end program\n",
    "    call_print_colors()\n",
    "    actual = capsys.readouterr()[0].strip()\n",
    "    expected = 'blue\\nbye'\n",
    "    assert actual == expected\n",
    "\n",
    "\n",
    "@patch(\"builtins.input\", side_effect=['green', 'quit'])\n",
    "def test_one_invalid_color_then_quit(input_mock, capsys):\n",
    "    # user enters green which is not in VALID_COLORS so continue the loop,\n",
    "    # user then enters quit so loop breaks (end function / program)\n",
    "    call_print_colors()\n",
    "    actual = capsys.readouterr()[0].strip()\n",
    "    expected = f'{NOT_VALID}\\nbye'\n",
    "    assert actual == expected\n",
    "\n",
    "\n",
    "@patch(\"builtins.input\", side_effect=['white', 'red', 'quit'])\n",
    "def test_invalid_then_valid_color_then_quit(nput_mock, capsys):\n",
    "    # white is not a valid color so continue the loop,\n",
    "    # then user enters red which is valid so print it, then quit\n",
    "    call_print_colors()\n",
    "    actual = capsys.readouterr()[0].strip()\n",
    "    expected = f'{NOT_VALID}\\nred\\nbye'\n",
    "    assert actual == expected\n",
    "\n",
    "\n",
    "@patch(\"builtins.input\", side_effect=['yellow', 'orange', 'quit'])\n",
    "def test_valid_then_invalid_color_then_quit(input_mock, capsys):\n",
    "    # yellow is a valid color so print it, user then enters orange\n",
    "    # which is not a valid color so continue loop, lastly user\n",
    "    # enters quit so exit loop = reaching end function / program\n",
    "    call_print_colors()\n",
    "    actual = capsys.readouterr()[0].strip()\n",
    "    expected = f'yellow\\n{NOT_VALID}\\nbye'\n",
    "    assert actual == expected\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a2b7e5",
   "metadata": {},
   "source": [
    "* Here we also have the `patch` function from the unittest.mock library.\n",
    "* It replaces defined library calls in the tested function (here `input`: save command line entry)\n",
    "* Solution is less complicated than the tests\n",
    "* An infinite loop asking for input is finished when the input value is quit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b1baa2",
   "metadata": {},
   "source": [
    "~~~\n",
    "VALID_COLORS = ['blue', 'yellow', 'red']\n",
    "\n",
    "\n",
    "def print_colors():\n",
    "    \"\"\"In the while loop ask the user to enter a color,\n",
    "       lowercase it and store it in a variable. Next check: \n",
    "       - if 'quit' was entered for color, print 'bye' and break. \n",
    "       - if the color is not in VALID_COLORS, print 'Not a valid color' and continue.\n",
    "       - otherwise print the color in lower case.\"\"\"\n",
    "    while True:\n",
    "        color = input(\"Enter a color:\").lower()\n",
    "        if color == 'quit':\n",
    "            print('bye')\n",
    "            break\n",
    "        elif color not in VALID_COLORS:\n",
    "            print(\"Not a valid color\")\n",
    "        else:\n",
    "            print(color)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print_colors()\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98184a8",
   "metadata": {},
   "source": [
    "~~~\n",
    "============================= test session starts ==============================\n",
    "...\n",
    "\n",
    "test_colors.py::test_straight_quit PASSED                                [ 16%]\n",
    "test_colors.py::test_one_valid_color_then_quit PASSED                    [ 33%]\n",
    "test_colors.py::test_title_cased_color_is_fine_too PASSED                [ 50%]\n",
    "test_colors.py::test_one_invalid_color_then_quit PASSED                  [ 66%]\n",
    "test_colors.py::test_invalid_then_valid_color_then_quit PASSED           [ 83%]\n",
    "test_colors.py::test_valid_then_invalid_color_then_quit PASSED           [100%]\n",
    "\n",
    "============================== 6 passed in 0.01s ===============================\n",
    "\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82e4868",
   "metadata": {},
   "source": [
    "Running the code\n",
    "~~~\n",
    "$ python colors.py \n",
    "Enter a color:red\n",
    "red\n",
    "Enter a color:Blue\n",
    "blue\n",
    "Enter a color:quit\n",
    "bye\n",
    "\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce87fe59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
